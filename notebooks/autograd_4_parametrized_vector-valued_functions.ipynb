{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3ae5c6",
   "metadata": {},
   "source": [
    "# Parametrized linear vector-valued function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4d691",
   "metadata": {},
   "source": [
    "Let $f: \\mathbb{R^n} \\times \\mathbb{R}^{p} \\rightarrow \\mathbb{R}^m$ be a parametraized vector field given by\n",
    "$$\n",
    "f(x; \\theta) = f(x; A, b) = x^T A + b^T, \\quad A \\in \\mathbb{R}^{n \\times m}, \\quad b \\in \\mathbb{R}^m, \\quad p = n(m + 1).\n",
    "$$\n",
    "Its partial derivatives are\n",
    "$$\n",
    "\\frac{\\partial}{\\partial a_{ij}}f(x, \\theta) = x_i, \\quad \n",
    "\\frac{\\partial}{\\partial b_j}f(x, \\theta) = 1 .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47ad0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef0003e",
   "metadata": {},
   "source": [
    "## backward method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c05ee36",
   "metadata": {},
   "source": [
    "1. no batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d110dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, a, b):\n",
    "    return torch.matmul(a, x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "068ab25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1635, -1.1557])\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "m = 3\n",
    "\n",
    "x = torch.randn(n, requires_grad=False, dtype=torch.float)\n",
    "a = torch.randn((m, n), requires_grad=True, dtype=torch.float)\n",
    "b = torch.randn(m, requires_grad=True, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "789ef5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = f(x, a, b)\n",
    "basis_vectors = torch.eye(m)\n",
    "v = basis_vectors[0]\n",
    "y.backward(v, retain_graph=True)\n",
    "    \n",
    "print(a.grad.shape)\n",
    "print(b.grad.shape)\n",
    "\n",
    "a.grad.zero_()\n",
    "b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57165a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1635, -1.1557],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]])\n",
      "tensor([1., 0., 0.])\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.1635, -1.1557],\n",
      "        [ 0.0000,  0.0000]])\n",
      "tensor([0., 1., 0.])\n",
      "tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.1635, -1.1557]])\n",
      "tensor([0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# evaluate f\n",
    "y = f(x, a, b)\n",
    "\n",
    "# basis vectors\n",
    "basis_vectors = torch.eye(m)\n",
    "\n",
    "# preallocate jacobian matrix\n",
    "p = n * (m+1)\n",
    "jac_y = torch.empty(m, p)\n",
    "\n",
    "for i, v in enumerate(basis_vectors):\n",
    "    \n",
    "    # use vector-Jacobian product\n",
    "    y.backward(v, retain_graph=True)\n",
    "    \n",
    "    # save gradients\n",
    "    print(a.grad)\n",
    "    print(b.grad)\n",
    "    #jac_y[i, 1] = x2.grad\n",
    "    #jac_y[i, 2] = x3.grad\n",
    "    \n",
    "    # reset gradients\n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dbca27bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a5f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch.autograd.functional import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f040ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1968, -0.0537],\n",
       "         [ 0.2123,  0.5456],\n",
       "         [-0.4865,  0.0271]]),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobian(model, (x,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694de3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdccfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preallocate Jacobian matrix with respect to the coefficients\n",
    "J = torch.empty(batch_size, 9)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    # use vector-Jacobian product\n",
    "    v = torch.eye(batch_size)[i].reshape(batch_size, 1)\n",
    "    f.backward(v, retain_graph=True)\n",
    "    \n",
    "    # save gradients\n",
    "    J[i, 0] = a.grad\n",
    "    J[i, 1] = b.grad\n",
    "    \n",
    "    # reset gradients\n",
    "    a.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "# show Jacobian\n",
    "print(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a8bbe",
   "metadata": {},
   "source": [
    "## grad() method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa6fa1",
   "metadata": {},
   "source": [
    "## jacobian() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "274ea859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd.functional import jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28d8e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jac_y_a, jac_y_b = jacobian(lambda a, b : f(x, a, b), (a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "203a2ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3, 2]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac_y_a.shape, jac_y_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15f10152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, jac_y_a, jac_y_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286a7956",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
